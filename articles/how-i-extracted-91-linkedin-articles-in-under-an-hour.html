<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How I Extracted 91 LinkedIn Articles in Under an Hour — PaddySpeaks</title>
    <meta name="description" content="I had 91 articles trapped inside LinkedIn. With Claude as my AI co-pilot, I extracted, converted, categorized, and deployed them all to my own website in under an hour.">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,500;0,600;0,700;0,800;1,400;1,500;1,600&amp;family=Source+Serif+4:ital,opsz,wght@0,8..60,300;0,8..60,400;0,8..60,500;0,8..60,600;1,8..60,300;1,8..60,400&amp;family=JetBrains+Mono:wght@300;400;500&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../style.css">
</head>
<body>

<div class="page-frame"></div>
<div class="reading-progress" id="readingProgress"></div>
<div class="top-bar"><span>Est. 2026</span><span>Philosophy · Technology · Wisdom</span><a href="https://linkedin.com/in/paddyiyer" target="_blank" rel="noopener">LinkedIn &nearr;</a></div>
<header class="masthead"><h1><a href="../index.html">Paddy<span>Speaks</span></a></h1><p class="masthead-tagline">Where ancient wisdom meets the architecture of tomorrow</p>
<div class="masthead-rule"></div>
</header>
<nav class="nav-bar"><a href="../index.html">Journal</a><a href="../index.html#philosophy">Philosophy</a><a href="../index.html#technology">Technology</a><a href="../index.html#ai">AI &amp; Future</a><a href="../index.html#archive">Archive</a><a href="../about.html">About</a></nav>
<div class="article-page">
<a class="back-to-home" href="../index.html">&larr; All Articles</a>
<div>
<div class="article-hero"><span class="tag">ai</span><h1>How I Extracted 91 LinkedIn Articles in Under an Hour</h1><p class="subtitle">My content was trapped inside LinkedIn. Claude helped me break it free.</p>
<div class="article-meta"><span>By Paddy</span><span class="dot"></span><span>February 27, 2026</span><span class="dot"></span><span>5 min read</span></div>
</div>
<div class="article-content">

            <p class="drop-cap">I have been writing on LinkedIn for over five years. Philosophy, technology, data architecture, AI, the Bhagavad Gita applied to modern work &mdash; 91 articles, spanning six years of my thinking. And all of it was locked inside LinkedIn&rsquo;s walled garden. No export button. No &ldquo;download all.&rdquo; No API for your own content. Your writing, their platform, their rules.</p>

            <p>So I decided to break it all free. And with Claude as my AI co-pilot, I did it in <strong>under an hour</strong>.</p>

            <div class="ornament-divider">&starf; &starf; &starf;</div>

            <h2>The Problem: Your Content, Their Platform</h2>

            <p>LinkedIn does offer a data export through their settings. You go to <strong>Settings &gt; Data Privacy &gt; Get a copy of your data</strong>, select &ldquo;Articles,&rdquo; and wait. What you get back is a zip file containing raw HTML files &mdash; one per article. The markup is LinkedIn&rsquo;s proprietary format: inconsistent class names, embedded styles, metadata scattered across custom elements.</p>

            <p>It is your data, technically. But it is not <em>usable</em> data. Not without serious work.</p>

            <div class="callout case-study">
                <span class="callout-label">The Raw Numbers</span>
                <p><strong>96 HTML files</strong> exported from LinkedIn. Proprietary markup. No consistent structure. Dates in different formats. Images pointing to expired CDN links. Zero documentation on the format.</p>
            </div>

            <div class="ornament-divider">&starf; &starf; &starf;</div>

            <h2>The Solution: Claude + Python + GitHub Pages</h2>

            <p>Here is what I did, step by step, with Claude doing most of the heavy lifting:</p>

            <h3>Step 1: Parse LinkedIn&rsquo;s HTML</h3>

            <p>I asked Claude to write a custom Python HTML parser that could handle LinkedIn&rsquo;s messy export format. The parser extracts:</p>

            <ul>
                <li><strong>Title</strong> from the first &lt;h1&gt; tag</li>
                <li><strong>Publication date</strong> from LinkedIn&rsquo;s custom metadata elements</li>
                <li><strong>Hero image</strong> URL (if present)</li>
                <li><strong>Full article body</strong> &mdash; while stripping out LinkedIn&rsquo;s wrapper cruft</li>
            </ul>

            <p>The <code>LinkedInHTMLParser</code> class handles all of LinkedIn&rsquo;s quirks &mdash; nested divs, empty paragraphs, hashtag spam at the bottom of articles, and inconsistent date formatting.</p>

            <h3>Step 2: Clean, Categorize, and Transform</h3>

            <p>Raw parsing was not enough. Claude helped me build a processing pipeline that:</p>

            <ul>
                <li><strong>Cleans the content</strong> &mdash; strips empty paragraphs, removes LinkedIn hashtags, eliminates broken image references</li>
                <li><strong>Categorizes every article</strong> &mdash; using keyword matching against four categories: AI &amp; Future, Philosophy, Technology, and Life</li>
                <li><strong>Generates URL-friendly slugs</strong> from article titles</li>
                <li><strong>Estimates reading time</strong> (word count &divide; 200 words per minute)</li>
                <li><strong>Extracts first paragraphs</strong> for meta descriptions and subtitle cards</li>
            </ul>

            <h3>Step 3: Generate a Beautiful Website</h3>

            <p>Claude did not just dump the content into plain HTML. It generated a complete, styled website with:</p>

            <ul>
                <li>A <strong>homepage with horizontal-scrolling article cards</strong></li>
                <li>Individual <strong>article pages with reading progress bars</strong></li>
                <li>A <strong>consistent design system</strong> &mdash; custom CSS with serif typography, warm tones, and a literary aesthetic</li>
                <li><strong>Category navigation</strong> so readers can browse by topic</li>
                <li><strong>Responsive design</strong> that works on mobile, tablet, and desktop</li>
            </ul>

            <h3>Step 4: Deploy on GitHub Pages</h3>

            <p>The entire site is static HTML and CSS. No frameworks. No build tools. No dependencies. Push to GitHub, enable Pages, point a custom domain, done. <strong>paddyspeaks.com</strong> was live.</p>

            <div class="stat-row">
                <div class="stat-card">
                    <span class="stat-num">91</span>
                    <span class="stat-label">Articles extracted</span>
                </div>
                <div class="stat-card">
                    <span class="stat-num">&lt;1hr</span>
                    <span class="stat-label">Total time spent</span>
                </div>
                <div class="stat-card">
                    <span class="stat-num">0</span>
                    <span class="stat-label">Frameworks used</span>
                </div>
            </div>

            <div class="ornament-divider">&starf; &starf; &starf;</div>

            <h2>What Surprised Me</h2>

            <p>The speed was obvious. But what really surprised me was the <strong>quality of judgment</strong> Claude demonstrated:</p>

            <ul>
                <li>It <strong>correctly categorized</strong> articles about the Bhagavad Gita under Philosophy and articles about data mesh under Technology &mdash; without me labeling a single one</li>
                <li>It <strong>handled edge cases</strong> like articles with no date, duplicate filenames, and malformed HTML without crashing</li>
                <li>It <strong>designed a consistent aesthetic</strong> across 91 pages that looked like a human designer had spent days on it</li>
                <li>It <strong>knew when to ask</strong> and when to just make a reasonable decision and move forward</li>
            </ul>

            <p>This was not &ldquo;AI generates slop.&rdquo; This was a genuine collaboration. I provided the vision and direction. Claude handled the tedious, complex, error-prone work of parsing, transforming, and generating 91 perfectly formatted pages.</p>

            <div class="ornament-divider">&starf; &starf; &starf;</div>

            <h2>The Bigger Point</h2>

            <p>This is what AI should be. Not replacing your thinking &mdash; <strong>amplifying your ability to act on it</strong>.</p>

            <p>I have been meaning to liberate my writing from LinkedIn for years. The thought of manually copying 91 articles, formatting them, building a site, categorizing everything &mdash; it always felt like a weekend project that would stretch into weeks. So I never did it.</p>

            <p>With Claude, I went from &ldquo;I should really do this someday&rdquo; to &ldquo;it is live&rdquo; in <strong>under an hour</strong>.</p>

            <div class="callout case-study">
                <span class="callout-label">The Takeaway</span>
                <p>Your content should live where <strong>you</strong> control it. Not inside a platform that can change its algorithm, paywall your reach, or shut down your profile tomorrow. If you have years of writing trapped in LinkedIn, Medium, or anywhere else &mdash; get it out. AI makes the migration trivially easy now.</p>
            </div>

            <div class="ornament-divider">&starf; &starf; &starf;</div>

            <h2>How You Can Do This Too</h2>

            <ol>
                <li><strong>Export your LinkedIn data</strong> &mdash; Settings &gt; Data Privacy &gt; Get a copy of your data &gt; Select &ldquo;Articles&rdquo;</li>
                <li><strong>Use Claude</strong> to write a parser for the HTML exports (or use mine &mdash; the code is open source on GitHub)</li>
                <li><strong>Generate your site</strong> &mdash; let Claude handle the HTML/CSS generation with a design you love</li>
                <li><strong>Deploy on GitHub Pages</strong> &mdash; free hosting, custom domain support, zero maintenance</li>
            </ol>

            <p>The entire pipeline is two Python scripts and a CSS file. No React. No Next.js. No npm install that downloads half the internet. Just HTML, CSS, and your words &mdash; <strong>finally free</strong>.</p>

            <div class="ornament-divider">&starf; &starf; &starf;</div>

            <p>Six years of writing. Ninety-one articles. One hour. One AI. Zero excuses left for keeping your content locked inside someone else&rsquo;s platform.</p>

            <p><strong>Your words deserve a home you own.</strong></p>

</div>

<div class="share-row">
    <span>Share this article:</span>
    <a href="https://twitter.com/intent/tweet?text=How+I+Extracted+91+LinkedIn+Articles+in+Under+an+Hour&url=" target="_blank" rel="noopener">Twitter/X</a>
    <a href="https://www.linkedin.com/sharing/share-offsite/?url=" target="_blank" rel="noopener">LinkedIn</a>
</div>

</div>
</div>

<footer class="footer">
    <div class="footer-inner">
        <p>&copy; 2026 PaddySpeaks. All rights reserved.</p>
        <p>
            <a href="https://linkedin.com/in/paddyiyer" target="_blank" rel="noopener">LinkedIn</a> &middot;
            <a href="https://twitter.com/paddyiyer" target="_blank" rel="noopener">Twitter/X</a>
        </p>
    </div>
</footer>

<script>
window.addEventListener('scroll', function() {
    const docHeight = document.documentElement.scrollHeight - window.innerHeight;
    const scrolled = (window.scrollY / docHeight) * 100;
    document.getElementById('readingProgress').style.width = scrolled + '%';
});
</script>

</body>
</html>
