<html>
<head>
  <title>AI Buzzwords Decoded </title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img src="https://media.licdn.com/mediaD5612AQHSdYbUEoUoDg" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/ai-buzzwords-decoded-paddy-iyer-vid8c">AI Buzzwords Decoded </a></h1>
    <p class="created">Created on 2026-02-10 20:37</p>
  <p class="published">Published on 2026-02-10 21:41</p>
  <div><p>LLMs, RAG, AI Agents, MCP, A2A — explained like you're chatting with a friend, not reading a textbook. With animated visual examples you'll actually remember.</p><h3>What's Inside</h3><ol><li><p><strong>LLMs — The Brainy Parrot→</strong></p></li><li><p><strong>AI Assistants — The Friendly Face→</strong></p></li><li><p><strong>RAG — The Open-Book Student→</strong></p></li><li><p><strong>AI Agents — The Self-Driving Employee→</strong></p></li><li><p><strong>MCP — The Universal Plug (USB-C for AI)→</strong></p></li><li><p><strong>A2A — Agents Talking to Each Other→</strong></p></li><li><p><strong>Low-Code AI — Build Without Coding→</strong></p></li><li><p><strong>The Big Picture — How It All Fits→</strong></p></li></ol><h2>Concept 1 - LLM — Large Language Model</h2><p></p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQHkSAGzZi2VKQ" src="https://media.licdn.com/dms/image/v2/D5612AQHkSAGzZi2VKQ/article-inline_image-shrink_1500_2232/B56ZxJYt4lHIAU-/0/1770757745416?e=1773878400&amp;v=beta&amp;t=wIL0b1Ipqms98uV5d6WPATxJAnk0Uw0WzRzKZFSB3n4"><figcaption></figcaption></figure><p>Think of an LLM as a <strong>supercharged autocomplete on steroids</strong>. You know how your phone suggests the next word when you're typing a message? An LLM does that, but it's read millions of books, websites, and conversations first. So its "guesses" are really, really good.</p><p>It doesn't truly "understand" things the way you and I do. It's more like a parrot that's read every library on Earth — <strong>it mimics human language patterns so well that it feels like intelligence</strong>. When you type "What's the capital of France?", it doesn't "know" Paris. It predicts that "Paris" is the most likely next word given everything it's learned.</p><p>▶ LLM in action: You ask → the LLM brain processes patterns → generates a human-like answer word by word</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQGd9uR4yNENEA" src="https://media.licdn.com/dms/image/v2/D5612AQGd9uR4yNENEA/article-inline_image-shrink_1500_2232/B56ZxJahbXIcAU-/0/1770758218557?e=1773878400&amp;v=beta&amp;t=CDZiboYZrc7MSYbrjoYyTPSoNxUG9SybojllpdtVRkQ"><figcaption></figcaption></figure><p><strong>Real-world examples:</strong> GPT-4 (OpenAI), Claude (Anthropic), Gemini (Google), Llama (Meta), and Mistral are all LLMs. Some are massive (hundreds of billions of parameters), while others are smaller — called <strong>SLMs (Small Language Models)</strong> — optimized for speed, privacy, or running on your phone.</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQEXdUGvYO6RrQ" src="https://media.licdn.com/dms/image/v2/D5612AQEXdUGvYO6RrQ/article-inline_image-shrink_1500_2232/B56ZxJa1OiK4AU-/0/1770758296822?e=1773878400&amp;v=beta&amp;t=Jec9wDbf5WRMtlq9fEA1LfYDvGP3L_fixTWRFMSyIgw"><figcaption></figcaption></figure><h2>Concept 2 - AI Assistants — The Friendly Face</h2><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQGzAiuIP4O6hg" src="https://media.licdn.com/dms/image/v2/D5612AQGzAiuIP4O6hg/article-inline_image-shrink_1500_2232/B56ZxJZusWJIAU-/0/1770758010400?e=1773878400&amp;v=beta&amp;t=45JkYMrRyEC5NhKcwrjUCA9vPf77e1zsfU2g-VR-v0o"><figcaption></figcaption></figure><p>If the LLM is the engine, the <strong>AI Assistant is the car you actually drive</strong>. It's the chat interface, the friendly bubble where you type questions and get answers. ChatGPT, Claude, Gemini, DeepSeek — these are all AI Assistants powered by LLMs underneath.</p><p>The assistant wraps the raw LLM in a user-friendly package. It adds safety filters, conversation memory (within a session), personality, and formatting. Without the assistant layer, talking to a raw LLM would be like talking to a savant who has no social skills — technically brilliant but hard to work with.</p><p>▶ Raw LLM (confusing terminal output) vs AI Assistant (friendly, formatted, conversational)</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQFOGOYJWGdwbQ" src="https://media.licdn.com/dms/image/v2/D5612AQFOGOYJWGdwbQ/article-inline_image-shrink_1500_2232/B56ZxJa6BwIEAY-/0/1770758319054?e=1773878400&amp;v=beta&amp;t=aFojmNngY82b227f9B88QYWDcwSGoNa5c9lBobhsVU0"><figcaption></figcaption></figure><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQFhfJGrDzjDkg" src="https://media.licdn.com/dms/image/v2/D5612AQFhfJGrDzjDkg/article-inline_image-shrink_1000_1488/B56ZxJa.2.JgAU-/0/1770758338786?e=1773878400&amp;v=beta&amp;t=pb4MyOk7JGB1-alMSYls4vDD4pxzLfwc6_IsB0qQcO8"><figcaption></figcaption></figure><h2>Concept 3 RAG — Retrieval-Augmented Generation</h2><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQFI_9Ho-eWnBA" src="https://media.licdn.com/dms/image/v2/D5612AQFI_9Ho-eWnBA/article-inline_image-shrink_1000_1488/B56ZxJZ_icKQAQ-/0/1770758078952?e=1773878400&amp;v=beta&amp;t=Fys5Cwajbc3F6CHFFC3v2BDbc-uq7z2mVTj5RhSXbMo"><figcaption></figcaption></figure><p>Here's the big problem with LLMs: <strong>they only know what they were trained on</strong>. Ask about your company's internal HR policy? They'll guess — or worse, confidently make something up (this is called a "hallucination"). Ask about something that happened yesterday? They have no clue.</p><p><strong>RAG is the solution.</strong> Instead of relying solely on the LLM's memorized knowledge, RAG first goes and <strong>retrieves relevant documents</strong> from your actual data (PDFs, databases, wikis, spreadsheets), then feeds those documents to the LLM so it can generate an answer grounded in real, accurate, up-to-date information.</p><p>▶ RAG pipeline: Question → Search your docs → Retrieve relevant chunks → Feed to LLM → Grounded answer</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQHKnbg5huyCeg" src="https://media.licdn.com/dms/image/v2/D5612AQHKnbg5huyCeg/article-inline_image-shrink_1500_2232/B56ZxJbFJZKcAU-/0/1770758364619?e=1773878400&amp;v=beta&amp;t=fSD9zafQcL3-4u6H2wctqgaNrw__VceSXJv3DUViefw"><figcaption></figcaption></figure><p><strong>How it works under the hood:</strong> Your documents (PDFs, web pages, wikis) get chopped into small chunks. Each chunk gets converted into a "vector embedding" — basically a list of numbers that captures its meaning. These get stored in a special <strong>vector database</strong>. When you ask a question, your question also gets converted into numbers, and the system finds the chunks that are most "mathematically similar" to your question. Those chunks get handed to the LLM as context.</p><p><strong>Why it matters:</strong> RAG reduces hallucinations, keeps answers up-to-date, and lets you build AI assistants grounded in YOUR data — without retraining the entire model. It's the backbone of every "chat with your documents" tool you've seen.</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQH3cJ45Fgge4w" src="https://media.licdn.com/dms/image/v2/D5612AQH3cJ45Fgge4w/article-inline_image-shrink_1000_1488/B56ZxJbKZ2JoAQ-/0/1770758386050?e=1773878400&amp;v=beta&amp;t=4nF59MRo-xtggtBEbBPLLclCYVMMFQnbqbvov6YmlCo"><figcaption></figcaption></figure><h2>Concept 4 AI Agents — The Self-Driving Employee</h2><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQH8hMY_IrQT2A" src="https://media.licdn.com/dms/image/v2/D5612AQH8hMY_IrQT2A/article-inline_image-shrink_1000_1488/B56ZxJbSBUHYAQ-/0/1770758417733?e=1773878400&amp;v=beta&amp;t=uIyaZQmQkCaNbSoplyP8DjSNcshKNWvlDgI0cjk1cUs"><figcaption></figcaption></figure><p>This is where things get genuinely exciting. LLMs answer questions. RAG makes those answers accurate. But <strong>AI Agents actually DO things</strong>. They don't just tell you "here's how to book a flight" — they go ahead and book the flight.</p><p>An AI Agent is an LLM with superpowers: it can <strong>think, plan, decide which tools to use, take action, check if it worked, and adjust</strong>. It's like giving the LLM not just a brain, but hands, feet, and a to-do list.</p><p>▶ Agent trip planner: You say "plan my trip" → Agent thinks, calls APIs, checks calendar, delivers full itinerary</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQH-gKHLrEsjRQ" src="https://media.licdn.com/dms/image/v2/D5612AQH-gKHLrEsjRQ/article-inline_image-shrink_1500_2232/B56ZxJbhbDIcAU-/0/1770758480393?e=1773878400&amp;v=beta&amp;t=tRd_XrtAyeCoReTDKXo_7cc8tcPxaippRCV4vJnbWU4"><figcaption></figcaption></figure><h3>From Recipe Reader to Full-Service Chef</h3><p>If an LLM is a chef who gives you recipes, an AI Agent is a chef who checks what's in your fridge, drives to the store for missing ingredients, cooks the meal, sets the table, and texts your guests the dinner time. It doesn't just know — it acts autonomously to reach a goal.</p><p><strong>The key difference from a basic chatbot:</strong> Traditional chatbots follow rigid, pre-scripted rules (if customer says X, respond with Y). AI Agents use the LLM's reasoning to dynamically figure out the best next step. They can handle edge cases, switch strategies mid-task, and use multiple tools in sequence — all without being explicitly programmed for every scenario.</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQF0UL5pAo2d8A" src="https://media.licdn.com/dms/image/v2/D5612AQF0UL5pAo2d8A/article-inline_image-shrink_1500_2232/B56ZxJbrW.HEAU-/0/1770758521035?e=1773878400&amp;v=beta&amp;t=RG5VPLM89oUgZWtI3byK4g2oLYw0Qudn9RlJepzpVTA"><figcaption></figcaption></figure><h2>Concept 5 MCP — Model Context Protocol</h2><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQF2T5Q3KFHhlg" src="https://media.licdn.com/dms/image/v2/D5612AQF2T5Q3KFHhlg/article-inline_image-shrink_1000_1488/B56ZxJb0dBHYAQ-/0/1770758557475?e=1773878400&amp;v=beta&amp;t=0TSg2_C_-gzPFf3Q18N1hID90oUkpxiyXqYB36WgJWY"><figcaption></figcaption></figure><p>Now here's the problem: if your AI Agent needs to talk to your email, your database, your calendar, your CRM, and your file system — someone has to write custom code connecting each one. That's messy, fragile, and doesn't scale.</p><p><strong>MCP is the USB-C of AI.</strong> Developed and open-sourced by Anthropic, it's a standard protocol — a universal plug — that lets any AI model connect to any tool, database, or data source through one consistent interface. Just like USB-C lets you charge your phone, connect a monitor, and transfer files all through one port, MCP lets your AI agent access emails, databases, APIs, and files all through one standardized connection.</p><p>▶ MCP in action: One AI agent, one protocol, connected to Email, Database, Analytics, Files — data flowing in real-time</p><p><strong>What MCP exposes to the AI — three key primitives:</strong> <strong>Tools</strong> — callable functions the AI can use to take actions (send email, query database, get weather). <strong>Resources</strong> — read-only documents the AI can reference (policy docs, product manuals, FAQs). <strong>Prompt Templates</strong> — reusable instructions that guide how the AI responds in specific situations.</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQF5UMnV2gcqWg" src="https://media.licdn.com/dms/image/v2/D5612AQF5UMnV2gcqWg/article-inline_image-shrink_400_744/B56ZxJcEeGJgAY-/0/1770758623913?e=1773878400&amp;v=beta&amp;t=thoXu7I0vo96TKUAQotBWF-c6lRg3kRvPMalG52JffM"><figcaption></figcaption></figure><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQH_UaQA0d9t0w" src="https://media.licdn.com/dms/image/v2/D5612AQH_UaQA0d9t0w/article-inline_image-shrink_1000_1488/B56ZxJcIN4KQAQ-/0/1770758639243?e=1773878400&amp;v=beta&amp;t=rO8A5xrBpcmrEyyYDYrc4RXD3-plxOdYomFODo4Qb58"><figcaption></figcaption></figure><h2>Concept 6 A2A — Agent-to-Agent Protocol</h2><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQH5tuR5r8C-RA" src="https://media.licdn.com/dms/image/v2/D5612AQH5tuR5r8C-RA/article-inline_image-shrink_1000_1488/B56ZxJcRZvKIAQ-/0/1770758676127?e=1773878400&amp;v=beta&amp;t=3d9YW5ajQsPGqX8N8Z6oD1kGT6DmPeBFW5nFNs4wTWY"><figcaption></figcaption></figure><p>MCP is about <strong>one agent connecting to many tools</strong>. But what happens when you have <strong>multiple specialized agents that need to work together</strong>? That's where A2A comes in.</p><p><strong>A2A (Agent-to-Agent)</strong>, open-sourced by Google, is a protocol that lets AI agents talk directly to each other — delegate tasks, share results, and collaborate. Think of it as the group chat protocol for AI agents.</p><p>▶ A2A collaboration: Researcher finds sources → Writer drafts → Editor reviews and publishes</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQGzAAOYd53T6Q" src="https://media.licdn.com/dms/image/v2/D5612AQGzAAOYd53T6Q/article-inline_image-shrink_1000_1488/B56ZxJcZRXHoAQ-/0/1770758709269?e=1773878400&amp;v=beta&amp;t=VpfU7UOr-qeyLGiCK1jlvk49fjzBD5iYMNIfdqPgFrU"><figcaption></figcaption></figure><p><strong>The key insight:</strong> You don't have to choose between MCP and A2A. An agent can use MCP to access tools AND use A2A to talk with other agents. They're complementary. MCP = "how do I use this tool?" A2A = "hey other agent, can you handle this part?"</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQEvfWcLFZDxAA" src="https://media.licdn.com/dms/image/v2/D5612AQEvfWcLFZDxAA/article-inline_image-shrink_1500_2232/B56ZxJcifIH0AU-/0/1770758747088?e=1773878400&amp;v=beta&amp;t=5fzm-Ig9ps5fM3coE1QmbzjOD2-bV70TeQ0T9LVNqcE"><figcaption></figcaption></figure><h2>Concept 7 Low-Code AI — Build Without Coding</h2><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQHnKlea2kgWOw" src="https://media.licdn.com/dms/image/v2/D5612AQHnKlea2kgWOw/article-inline_image-shrink_1000_1488/B56ZxJcqegHEAQ-/0/1770758780055?e=1773878400&amp;v=beta&amp;t=CsoW9RZBc7veLolKjMPotgj7lKqCLS5yzLd_S6nn7-s"><figcaption></figcaption></figure><p>Here's the best part: <strong>you don't need to be a programmer to build all of this</strong>. Platforms like <strong>Zapier, Make, and n8n</strong> let you wire together LLMs, APIs, tools, and data sources through visual drag-and-drop workflows. No Python required.</p><p>▶ Low-code workflow: Email arrives → AI summarizes → Posts to Slack → Logs in spreadsheet. Zero code. Runs 24/7.</p><p>Even if these platforms don't fully implement MCP, you can still build <strong>MCP-inspired logic</strong>: sharing memory between steps, routing data between AI models, and managing smart automations across your systems. The original article highlights event-driven AI actions like <strong>"New merge request → AI reviews the code"</strong> or <strong>"New email → AI summarizes it."</strong></p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQFjucBfM-4uyQ" src="https://media.licdn.com/dms/image/v2/D5612AQFjucBfM-4uyQ/article-inline_image-shrink_1500_2232/B56ZxJc0ePIAAY-/0/1770758820751?e=1773878400&amp;v=beta&amp;t=hKO2IPIP20zr67OHVknhG3lcdbKuoQlPPoxWkji4Sok"><figcaption></figcaption></figure><h2>Concept 8 The Big Picture — How It All Connects</h2><p>Now let's zoom out. Each concept builds on the previous one, like layers of a cake:</p><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQGCGwCYs-aP6w" src="https://media.licdn.com/dms/image/v2/D5612AQGCGwCYs-aP6w/article-inline_image-shrink_1000_1488/B56ZxJdB8JJMAQ-/0/1770758875764?e=1773878400&amp;v=beta&amp;t=RXXB7GSLV5NpI1LY1n0FcbN-5iF_Ll7aGi9RvEH5dA0"><figcaption></figcaption></figure><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQHRNd_BCN8Vrg" src="https://media.licdn.com/dms/image/v2/D5612AQHRNd_BCN8Vrg/article-inline_image-shrink_400_744/B56ZxJdGASIoAY-/0/1770758892338?e=1773878400&amp;v=beta&amp;t=eIs1NMCehpU9Qrd5JWHzrAb_GlnCEQ0iP7OCTelxDFU"><figcaption></figcaption></figure><figure><img data-media-urn="urn:li:digitalmediaAsset:D5612AQH2EwI5ONrKqw" src="https://media.licdn.com/dms/image/v2/D5612AQH2EwI5ONrKqw/article-inline_image-shrink_400_744/B56ZxJdJv5HYAY-/0/1770758907589?e=1773878400&amp;v=beta&amp;t=Q16uTsZdAiX4a4uFPF_jJU8vi0fbgIFyGjjPf0AAK7w"><figcaption></figcaption></figure><h2>Credits: </h2><p>Inspired by <a href="https://blog.stackademic.com/understanding-ai-buzzwords-llm-rag-ai-agents-mcp-made-simple-9d00faff9b47" target="_blank">"Understanding AI Buzzwords" by Jihène Mejri on Stackademic</a></p><p></p></div>
</body>
</html>